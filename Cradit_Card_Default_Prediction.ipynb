{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "g-ATYxFrGrvw",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rushabhbhagat08/Cradit-Card-Default-Prediction/blob/main/Cradit_Card_Default_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member -** Rushabh Anilrao Bhagat"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is details of credit card holders of an \"important bank in Taiwan\" for the period April to September, 2005. The features available include some basic customer demographics (gender, education, marital status and age), available credit line, their history of payment/default for the six months mentioned (Apr--Sep '05), their bill amounts and their payment amounts for that period and a binary target variable indicating default the following month.\n",
        "\n",
        "The data was originally studied by the authors of the paper: Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480.\n",
        "\n",
        "I perform some EDA to understand the data and clean the data, engineer relevant features, build predictive models to predict default and perform some statistical analyses to obtain a greater understanding of the features and their interactions. I finish with some business case scenarios where the predictive model could be applied."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from scipy import stats\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn import metrics  \n",
        "# from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "# from sklearn.metrics import plot_precision_recall_curve\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "# from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "from pprint import pprint\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade xlrd"
      ],
      "metadata": {
        "id": "ng-ArUDdaOgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YPQz2chSYb3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "file_path=('/content/drive/MyDrive/Classification_project/Credit card default prediction /default of credit card clients (1).xls')\n",
        "cradit_crd_df=pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "riP6gv8bYnGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "cradit_crd_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arranged datasets "
      ],
      "metadata": {
        "id": "3b3VAHwYpXEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove a row \n",
        "cradit_crd_df=cradit_crd_df.drop(cradit_crd_df.index[[0,0]],axis=0)"
      ],
      "metadata": {
        "id": "njPorUH3gxPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change columns names\n",
        "update_col=['ID','LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6','DEF_PAY_NXT_MONTH']"
      ],
      "metadata": {
        "id": "wVvM3LfohB_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update columns name\n",
        "cradit_crd_df.columns=update_col"
      ],
      "metadata": {
        "id": "gnebxqiKhdqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#updated dataset\n",
        "cradit_crd_df=cradit_crd_df.astype('int')"
      ],
      "metadata": {
        "id": "UI1mITW6ix72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the information of all the dataset\n",
        "cradit_crd_df.info()"
      ],
      "metadata": {
        "id": "Nkn2MT_eGrb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows=cradit_crd_df.shape[0]\n",
        "columns=cradit_crd_df.shape[1]\n",
        "print(f\"The number of rows is {rows} and number of columns is {columns}.\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "eLoOKbhlOaoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "condition = bool(cradit_crd_df.duplicated(subset = 'ID').any())\n",
        "\n",
        "if condition:\n",
        "    print('There are duplicate IDs')\n",
        "else:\n",
        "    print('No duplicate IDs')"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identify outliers "
      ],
      "metadata": {
        "id": "gWbWS4GpO5Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cradit_crd_df[\"LIMIT_BAL\"].plot(kind=\"box\")\n",
        "plt.xlabel('Credit limit in NT$', fontweight='bold')\n",
        "plt.ylabel('# of Customers', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bRIuVKhpIUEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = cradit_crd_df.loc[cradit_crd_df['LIMIT_BAL']>900000]\n",
        "outliers"
      ],
      "metadata": {
        "id": "RDFPm6HSPLE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "cradit_crd_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no NaN/NULL record in the dataset, So we dont have to impute any record."
      ],
      "metadata": {
        "id": "hSm60USbbov3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check numerical columns"
      ],
      "metadata": {
        "id": "IaNBe3CBQPEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "cradit_crd_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "cradit_crd_df.describe().transpose()"
      ],
      "metadata": {
        "id": "FoQXIU3r2ldu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the data description said that the minimum value of pay_i's was -2, all of them have a minimum value of -2. Also marriage has a minimum value of 0 but the description said the minimum value is 1. And education has a maximum value of 6 while it was supposed to have a maximum value of 4. I'll take a closer look later.\n",
        "\n",
        "I notice that some of the bill_amti's are negative. Although surprising, it is not uncommon to have a negative balance because of merchant refunds or overpayments. The values are a bit on the higher side and I'll take another look later."
      ],
      "metadata": {
        "id": "laLRxfe4MlYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "UOiW-isgLCM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "IWp6SkWxLMuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the entries of the ID column\n",
        "print(cradit_crd_df[\"ID\"].value_counts())\n",
        "cradit_crd_df.drop([\"ID\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "EX3OMDG0dXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "cradit_crd_df.head()"
      ],
      "metadata": {
        "id": "LaPZwvDHBvdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
        "* X0 (ID): unique id value each row.\n",
        "\n",
        "* X1 (LIMIT_BAL): Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
        "\n",
        "* X2 (SEX): Gender (1 = male; 2 = female).\n",
        "\n",
        "* X3 (EDUCATION): Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "\n",
        "* X4 (MARRIAGE): Marital status (1 = married; 2 = single; 3 = others).\n",
        "\n",
        "* X5 (AGE): Age (year).\n",
        "\n",
        "* X6 (PAY_1) - X11 (PAY_6): History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6(PAY_1) = the repayment status in September, 2005; X7(PAY_2) = the repayment status in August, 2005; . . ....;X11(PAY_6) = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
        "\n",
        "* X12 (BILL_AMT1)-X17 (BILL_AMT6): Amount of bill statement (NT dollar). X12(BILL_AMT1) = amount of bill statement in September, 2005; X13(BILL_AMT2) = amount of bill statement in August, 2005; . . .; X17(BILL_AMT6) = amount of bill statement in April, 2005.\n",
        "\n",
        "* X18(PAY_AMT1)-X23 (PAY_AMT6): Amount of previous payment (NT dollar). X18(PAY_AMT1) = amount paid in September, 2005; X19 (PAY_AMT2) = amount paid in August, 2005; . . .;X23(PAY_AMT6) = amount paid in April, 2005.\n",
        "* DEF_PAY_NXT_MONTH: default payment status next month.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "pay=cradit_crd_df[['PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']]\n",
        "pay_melt=pd.melt(pay)\n",
        "print(pay_melt['value'].value_counts())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "QstWIM2OGFAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "y7wKpHpkGL5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will study the relationship between the features and credit card default. Although this is not definitive, it will give me a good understanding of the data. This will also help me make decisions about some of the features having values different than what was provided in the data description."
      ],
      "metadata": {
        "id": "T4mi17mMOBal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "def compare_default_across_features(df, col_name, dict_label={}):\n",
        "    \"\"\"\n",
        "    This function quantifies and displays the distribution of default across the various classes of a feature.\n",
        "    \n",
        "    INPUT:\n",
        "    - df - (pd.DataFrame) the dataframe\n",
        "    - col_name - (str) the column name of the feature being considered\n",
        "    - dict_label - (dictionary) a dictionary relating the values of the column to what they represent\n",
        "    \n",
        "    OUTPUT:\n",
        "    - Displays a bar plot showing the population distribution by feature values\n",
        "    - Displays and returns a cross-tab showing the rate of default across each feature value\n",
        "    - Displays a bar plot showing the population distribution and default by the feature values \n",
        "    \"\"\"\n",
        "\n",
        "    # Create a cross-tab and rename indices for readability\n",
        "    cross_tab = pd.crosstab(df[\"DEF_PAY_NXT_MONTH\"], df[col_name], margins=True, normalize=False)\n",
        "\n",
        "    # new_index=['Not Default','Default']\n",
        "\n",
        "    new_index = {0: \"Non-default proportion\", 1: \"Default proportion\"}\n",
        "    # new_index={'non_default':0,'default':1}\n",
        "    new_columns = dict_label\n",
        "\n",
        "    cross_tab.rename(index=new_index, columns=new_columns, inplace=True)\n",
        "\n",
        "    # Plot a bar graph showing population distribution by the feature values\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    i = cross_tab.shape[1] - 1\n",
        "    cross_tab.loc[\"All\"][0:i].plot.bar(rot=30, fontsize=14)\n",
        "    plt.title(\"Population Distribution by \" + col_name, fontsize=20)\n",
        "    plt.ylabel(\"count\")\n",
        "    # plt.add_legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Normalise the cross-tab and print it\n",
        "    cross_tab_norm = cross_tab / cross_tab.loc[\"All\"]\n",
        "    display(cross_tab_norm)\n",
        "\n",
        "    # Plot a bar graph showing population distribution by the feature values separating the defaulters and non-defaulters\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    ax = sns.countplot(x=col_name, hue='DEF_PAY_NXT_MONTH',data=df)\n",
        "    plt.title(\n",
        "        \"Population Distribution by \" + col_name + \" with default and non-default\",\n",
        "        fontsize=20,\n",
        "    )\n",
        "\n",
        "    # Return the normalised cross-tab\n",
        "    return cross_tab_norm"
      ],
      "metadata": {
        "id": "8CYpxLZFGI_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot bar chart since there will be multiple bars charts to plot\n",
        "def relationship_bar(column):\n",
        "   # Get the percentage of default by each group\n",
        "    default_by_group = pd.crosstab(index=cradit_crd_df['DEF_PAY_NXT_MONTH'],columns = cradit_crd_df[column], normalize = 'columns')\n",
        "      # Round up to 2 decimal\n",
        "    default_by_group = default_by_group.apply(lambda x: round(x,2))\n",
        "    \n",
        "    labels = default_by_group.columns\n",
        "    list1 = default_by_group.iloc[0].to_list()\n",
        "    list2 = default_by_group.iloc[1].to_list()\n",
        "    list1_name = \"No default\"\n",
        "    list2_name = \"Has default\"\n",
        "    title = f\"Default by {column}\"\n",
        "    xlabel = column\n",
        "    ylabel = \"Default percentage\"\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    bar_width = 0.5\n",
        "    \n",
        "    ax1 = ax.bar(labels,list1, bar_width, label = list1_name)\n",
        "    ax2 = ax.bar(labels,list2, bar_width, bottom = list1, label = list2_name)\n",
        "\n",
        "    ax.set_title(title, fontweight = \"bold\")\n",
        "    ax.set_xlabel(xlabel, fontweight = \"bold\")\n",
        "    ax.set_ylabel(ylabel, fontweight = \"bold\")\n",
        "    ax.legend(loc=\"best\")\n",
        "    \n",
        "    plt.xticks(list(range(len(labels))), labels,rotation=90)\n",
        "    plt.yticks(fontsize=9)\n",
        "\n",
        "    for r1, r2 in zip(ax1, ax2):\n",
        "        h1 = r1.get_height()\n",
        "        h2 = r2.get_height()\n",
        "        plt.text(r1.get_x() + r1.get_width() / 2., h1 / 2., f\"{h1:.0%}\", ha=\"center\", va=\"center\", color=\"white\", fontsize=9, fontweight=\"bold\")\n",
        "        plt.text(r2.get_x() + r2.get_width() / 2., h1 + h2 / 2., f\"{h2:.0%}\", ha=\"center\", va=\"center\", color=\"white\", fontsize=9, fontweight=\"bold\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JBHH2xVxHG4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "TOHAaUzzKe61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "zm-lxpPLHMYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is default proportion affected by gender?"
      ],
      "metadata": {
        "id": "zSQp0Ms0OPOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "from locale import normalize\n",
        "# Get the proportion of customers who had default payment in the next month (Oct.2005)? \n",
        "# About 22% customers had default payment next month\n",
        "\n",
        "x=cradit_crd_df['DEF_PAY_NXT_MONTH'].value_counts(normalize=True)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(x, colors=['springgreen', 'coral'], shadow=True, autopct='%1.2f%%', startangle=200)\n",
        "plt.legend(labels=['Not Default','Default'])\n",
        "plt.title(\" proportion of customers who had default payment in the next month\")"
      ],
      "metadata": {
        "id": "pAhPmnVtwPRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "Fsx5x4jEOit6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get SEX column's distribution. 1: male; 2: female\n",
        "# No undocumented SEX code\n",
        "data = cradit_crd_df['SEX'].value_counts().rename_axis('sex').reset_index(name='counts')\n",
        "data"
      ],
      "metadata": {
        "id": "ftrYOR7p26J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# plot the graph Of SEX column \n",
        "plt.figure(figsize=(10, 5))\n",
        "x= compare_default_across_features(cradit_crd_df, 'SEX', {1: \"Male\", 2: \"Female\"})"
      ],
      "metadata": {
        "id": "rhSVGXxp7VfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there are more female credit card holders, the default proportion among men is higher. I will do a hypothesis test to see if the difference is statistically significant.\n",
        "(1: default,0:non_default) \n",
        "Is default proportion affected by education?"
      ],
      "metadata": {
        "id": "y88ROKbY9vtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#From dataset description: EDUCATION: Education status (1=graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "print(cradit_crd_df['EDUCATION'].unique())\n",
        "cradit_crd_df['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "ZJ1b63zwQiqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#But we get 6 values so, we have replace 5,6,0 values \n",
        "cradit_crd_df['EDUCATION']=cradit_crd_df['EDUCATION'].replace({0:4,5:4,6:4})\n",
        "cradit_crd_df['EDUCATION'].value_counts().rename_axis('EDUCATION').reset_index(name='counts')"
      ],
      "metadata": {
        "id": "jPMmFuj1QuZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "o5cpMhfTIAkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# plot the graph of EDUCATION column \n",
        "x = compare_default_across_features(\n",
        "    cradit_crd_df,\n",
        "    \"EDUCATION\",\n",
        "    {\n",
        "        1: \"Grad School\",\n",
        "        2: \"University\",\n",
        "        3: \"High School\",\n",
        "        4: \"Others\",\n",
        "    },=\n",
        ")"
      ],
      "metadata": {
        "id": "pl9TQ4R084i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick glance shows that the default proportion decreases with higher education level. This would agree with my intuition because more educated people tend to have higher paying jobs which might make it easier for them to pay back their debts.\n",
        "\n",
        "As I mentioned earlier, I notice that there are education categories with values 0, 5 and 6 which are not explained by the data description. I could marge those data points, keep them with another cluster. Since there is an Others category, I will cluster them with that category."
      ],
      "metadata": {
        "id": "tTe5_IeiO7Rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "lxCsC02CI3jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is default proportion affected by marital status?"
      ],
      "metadata": {
        "id": "FeEj9zsRPRsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From dataset description: MARRIAGE: Marital status (1=married, 2=single, 3=others), but there is also 0\n",
        "print(cradit_crd_df['MARRIAGE'].value_counts())"
      ],
      "metadata": {
        "id": "N4pUsXZNRCDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have replace 0 value.\n",
        "cradit_crd_df[\"MARRIAGE\"] = cradit_crd_df[\"MARRIAGE\"].replace({0:3})\n",
        "print(cradit_crd_df['MARRIAGE'].value_counts().rename_axis('MARRIAGE').reset_index(name='counts'))"
      ],
      "metadata": {
        "id": "2KSA9rdQRsBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# plot the graph of MARRIAGE column\n",
        "x= compare_default_across_features(\n",
        "    cradit_crd_df,\n",
        "    \"MARRIAGE\",\n",
        "    {\n",
        "        1: \"Married\",\n",
        "        2: \"Single\",\n",
        "        3: \"Others\",\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "G6VgK2709npp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Married people have higher default proportions than single folks. While there are intuitive arguments for and against it, closer inspection is needed. For example, is there a difference between married men and married women?\n",
        "\n",
        "Also, I notice that there is a marriage category with value 0. Like earlier, since there is an Others category, I will cluster these points with that category. (This is done a bit later.)\n",
        "\n"
      ],
      "metadata": {
        "id": "6jlmim34CrWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "2EtqvrieJHl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the proportion of defaults correlated with age?\n",
        "\n",
        "Since age is a discrete variable, I have to figure out a way to bin the values. There are several ways to do this (including using the frequency and quantiles) but I will choose a simpler and more intuitive way by rounding their age to the lowest multiple of 10."
      ],
      "metadata": {
        "id": "2jpsdfTdVRIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the age bins\n",
        "cradit_crd_df['age_group'] = cradit_crd_df['AGE']//10\n",
        "age_group_names = [str(i) + '0s' for i in range(2,8)]\n",
        "age_dict = dict(zip(range(2,8), age_group_names))\n",
        "#cc_df['age_bin'] = pd.cut(X['age'], 6, labels=age_group_names)"
      ],
      "metadata": {
        "id": "QjNoYltC_SS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# plot the graph of AGE_GROUP column\n",
        "age_cross_tab = compare_default_across_features(cradit_crd_df, 'age_group', age_dict)"
      ],
      "metadata": {
        "id": "_KdzWQmJ_i26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is easy to see that default proportion is lowest for people in their 30s and then steadily rises with age.\n",
        "\n",
        "Is the default proportion affected by credit limit?\n",
        "\n",
        "Instead of binning the credit limits, I try to see if I can analyse any trends from a density plot."
      ],
      "metadata": {
        "id": "ff3xsExWXACJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "nA-uRDCkJWv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Make a boxplot to visualize credit limit and default payment next month\n",
        "# 1: default next month; 0: no default next month\n",
        "def0 = cradit_crd_df.loc[cradit_crd_df['DEF_PAY_NXT_MONTH'] == 0,'LIMIT_BAL']\n",
        "def1 = cradit_crd_df.loc[cradit_crd_df['DEF_PAY_NXT_MONTH'] == 1,'LIMIT_BAL']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot([def0, def1],  showfliers=False)\n",
        "ax.set_xticklabels(['No_default',\"Default\"],fontweight ='bold')\n",
        "ax.set_ylabel('Credit limit',fontweight ='bold')\n",
        "ax.set_title('Credit limit & default next month',fontweight ='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PDSS_AHmz_lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the plot, it seems that people with higher credit limit have significantly lower default proportion. Again, intuitively that is not surprising because the people who have higher credit limits must have displayed long periods of fiscal responsibility to reach that place."
      ],
      "metadata": {
        "id": "lYuRVFCZ0cG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#see our dataset\n",
        "cradit_crd_df.head().transpose()"
      ],
      "metadata": {
        "id": "tJt2gOslvnQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get statistic summary of bill statement columns\n",
        "# The min numbers are negative\n",
        "bill = cradit_crd_df[['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']]\n",
        "bill.describe(include='all').transpose()"
      ],
      "metadata": {
        "id": "OhBnK4NxvKHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "M8gY_3eiJ4st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Subset a dataframe with the records that have default\n",
        "has_default = cradit_crd_df[cradit_crd_df['HAS_DEF']== 1]\n",
        "\n",
        "default_trend = has_default[['PAY_6','PAY_5','PAY_4','PAY_3','PAY_2','PAY_1']].sum(axis=0)\n",
        "\n",
        "# Draw a line chart to show the trend. The lower the number, the shorter delayed payment\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(default_trend)\n",
        "plt.xticks(['PAY_6','PAY_5','PAY_4','PAY_3','PAY_2','PAY_1'],['Apr','May','Jun','Jul','Aug','Sep'])\n",
        "\n",
        "plt.xlabel('Months in 2005',fontweight='bold')\n",
        "plt.ylabel('Total delayed months',fontweight='bold')\n",
        "plt.title('Delayed payment trend',fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "gP8We1rf_Qsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Is there any bill amount that is greater than credit limit?\n",
        "condition1 = cradit_crd_df['BILL_AMT1'] > cradit_crd_df['LIMIT_BAL'] \n",
        "condition2 = cradit_crd_df['BILL_AMT2'] > cradit_crd_df['LIMIT_BAL'] \n",
        "condition3 = cradit_crd_df['BILL_AMT3'] > cradit_crd_df['LIMIT_BAL'] \n",
        "condition4 = cradit_crd_df['BILL_AMT4'] > cradit_crd_df['LIMIT_BAL'] \n",
        "condition5 = cradit_crd_df['BILL_AMT5'] > cradit_crd_df['LIMIT_BAL'] \n",
        "condition6 = cradit_crd_df['BILL_AMT6'] > cradit_crd_df['LIMIT_BAL'] \n",
        "\n",
        "large_bill = cradit_crd_df[condition1 | condition2 |condition3 | condition4 | condition5 | condition6]\n",
        "large_bill['DEF_PAY_NXT_MONTH'].value_counts(normalize=True)\n",
        "# x=cradit_crd_df['DEF_PAY_NXT_MONTH'].value_counts(normalize=True)\n"
      ],
      "metadata": {
        "id": "pWBDqQtz_7EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column \"HAS_DEF\" to indicate customers who have at least 1 default payment from PAY_1 to Pay_6\n",
        "# 0 : no default ; 1: has default\n",
        "\n",
        "def_condition =(cradit_crd_df.PAY_1>1) | (cradit_crd_df.PAY_2>1) | (cradit_crd_df.PAY_3>1) | (cradit_crd_df.PAY_4>1) | (cradit_crd_df.PAY_5>1) | (cradit_crd_df.PAY_6>1)\n",
        "cradit_crd_df.loc[def_condition, \"HAS_DEF\"] = 1\n",
        "cradit_crd_df.loc[cradit_crd_df.HAS_DEF.isna(), \"HAS_DEF\"] = 0\n"
      ],
      "metadata": {
        "id": "FUHgSowSTZpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new column see our dataset\n",
        "cradit_crd_df.head()"
      ],
      "metadata": {
        "id": "OVvuVNRDau8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 7- Scatter Plot"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Plotting the bill amount density plots and their scatter plots\n",
        "sns.pairplot(cradit_crd_df, vars=cradit_crd_df.columns[11:17], kind='scatter',hue= 'HAS_DEF')"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the bill amounts are skewed. If the model assumptions require symmetric/normal distributions, a log transformation or a Box-Cox transformation might be warranted.\n",
        "\n",
        "I will be using a MinMaxScaler later to scale the data given the presence of a lot of outliers."
      ],
      "metadata": {
        "id": "x39aY_ptcFsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chart-8 -- correlation Heatmap\n",
        "corr = cradit_crd_df.corr()\n",
        "plt.figure(figsize=(18, 15))\n",
        "sns.heatmap(corr, annot=True, vmin=-1.0, cmap='mako')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RS5dsMgMr0qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Inference"
      ],
      "metadata": {
        "id": "kOWpNS_uDEgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Is Default Affected by Gender?"
      ],
      "metadata": {
        "id": "pxEVg-iqDMdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does gender affect the default rate? I will try to answer this question with a hypothesis test. As is customary, I'll use a significance level of α=0.05\n",
        ". Then the bounds of the confidence interval are given by [α/2,1-α/2]=[0.25,0.975].\n",
        " \n",
        " \n"
      ],
      "metadata": {
        "id": "rWWapurRDTIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "lb, ub = (alpha / 2), 1 - (alpha / 2)\n",
        "ci_bounds = [lb, ub]"
      ],
      "metadata": {
        "id": "SZRwj2ukDBsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to test whether the proportion <b>Pm</b>\n",
        " of men defaulting is the same as the proportion <b>Pw</b>\n",
        " of women defaulting. Hence, my test statistic is the difference between <b>Pw</b>\n",
        " and <b>Pm</b>\n",
        ".\n",
        "\n",
        "I state the null Hypothesis and alternate Hypothesis.\n",
        "* H0: Pm=Pw\n",
        "\n",
        "* Ha: Pm≠Pw\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement "
      ],
      "metadata": {
        "id": "POgV1Pe6JrRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "HXkFub4QJzOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "ttest, pval = stats.ttest_ind(cradit_crd_df[cradit_crd_df['SEX'] == 1]['HAS_DEF'], cradit_crd_df[cradit_crd_df['SEX'] == 2]['HAS_DEF'], equal_var=False)"
      ],
      "metadata": {
        "id": "MUheRvKgGRyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to check the Pval is grater then 0.05\n",
        "print(pval)\n",
        "if pval<0.05:\n",
        "  print(\"Null Hypothesis is rejected\")\n",
        "else:\n",
        "  print(\"Alternate Hypothesis is rejected\")  "
      ],
      "metadata": {
        "id": "fketmG1XI4N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results the null hypotheis of Pm=Pw is rejected. "
      ],
      "metadata": {
        "id": "DFz6luljJWHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on my understanding of the data and conclusions from EDA, I engineer a few features."
      ],
      "metadata": {
        "id": "-sOxsv_56oAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having engineered the features, I see if some of the aggregated columns are correlated with default. A quick look does show some relation although I would have to do some statistical tests to see if that is significant.\n",
        "\n",
        "I draw a scatter plot of average payment amount and average bill amount and notice that there is a marked difference in slope in the line of best fit for the default and non-default class."
      ],
      "metadata": {
        "id": "CfI9F8ybIYB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I notice that about one third of the people whose average bill amount was more than the credit limit defaulted. As a result, I engineer a feature called overdraft which takes value 1 if the user defaulted at any point in the past 6 months."
      ],
      "metadata": {
        "id": "ywWkPMx6L7j6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the original data set, along with some minor data adjustments discussed earlier and the one-hot encoding of the marriage feature."
      ],
      "metadata": {
        "id": "1k9PXrohY3S6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains features that avoid multicollinearity in the model (and hence, statistically significant non-zero coefficients in a logistic model). I decide on this list by looking at the vif and deviance reduction and also at the feature importances of the models. The dataset is then scaled and the training set balanced.\n",
        "\n"
      ],
      "metadata": {
        "id": "FaLhHeUWZV7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Define predictor variables and target variable\n",
        "X = cradit_crd_df.drop(columns=['DEF_PAY_NXT_MONTH'])\n",
        "y = cradit_crd_df['DEF_PAY_NXT_MONTH']\n",
        "\n",
        "# Save all feature names as list\n",
        "feature_cols = X.columns.tolist() \n",
        "#print(feature_cols)\n",
        "# Extract numerical columns and save as a list for rescaling\n",
        "X_num = X.drop(columns=['SEX', 'EDUCATION', 'MARRIAGE', 'AGE'])\n",
        "num_cols = X_num.columns.tolist() \n",
        "print(num_cols)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Splitting"
      ],
      "metadata": {
        "id": "rVSJ51EOaRev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function that count for imbalances\n",
        "\n",
        "def data_split(x,y,imbalance=False):\n",
        "  '''\n",
        "This function will split the data according to the imbalance in the data set \n",
        "if imbalance is there in then use SMOTE Analysis   '''\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,shuffle=True, stratify=y, random_state=42)\n",
        "  if imbalance:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    sm = SMOTE(random_state = 42)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train.ravel())  \n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "0Y0mKAwC6hOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "f3J2_iT6abr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to rescale training data using StandardScaler\n",
        "def rescaling(X_train, X_test, numerical_cols):\n",
        "    \n",
        "    # Make copies of dataset\n",
        "    X_train_std = X_train.copy()\n",
        "    X_test_std = X_test.copy()\n",
        "    \n",
        "    # Apply standardization on numerical features only\n",
        "    for i in numerical_cols:\n",
        "        scl = StandardScaler().fit(X_train_std[[i]])     # fit on training data columns\n",
        "        X_train_std[i] = scl.transform(X_train_std[[i]]) # transform the training data columns\n",
        "        X_test_std[i] = scl.transform(X_test_std[[i]])   # transform the testing data columns\n",
        "    \n",
        "    return X_train_std,X_test_std"
      ],
      "metadata": {
        "id": "nCx_JUIM6z-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "djqpDoFFagXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall(model,X_test,y_test):\n",
        "  y_pred=model.predict(X_test)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    \n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "  F1 = 2 * (precision * recall) / (precision + recall)\n",
        "  print(f'Precision:{precision:.3f}\\nRecall:{recall:.3f}\\nF1 score:{F1:.3f}')"
      ],
      "metadata": {
        "id": "zowEhTzBQhbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "6-LPYgncZ9iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "wMNkdhUPaDSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "def logistic_regression(imbalance=False):\n",
        "  X_train, X_test, y_train, y_test=data_split(X,y,imbalance=imbalance)\n",
        "  X_train_std,X_test_std=rescaling(X_train,X_test,numerical_cols = num_cols)\n",
        "# Fit the Algorithm\n",
        "  clf_lr = LogisticRegression(random_state=42)\n",
        "  clf_lr.fit(X_train_std, y_train)\n",
        "  scores = cross_val_score(clf_lr, X_train_std, y_train, scoring =\"roc_auc\", cv = 5)\n",
        "  roc_auc_lr = np.mean(scores)*100\n",
        "  # print(roc_auc_lr)\n",
        "\n",
        "  if imbalance:\n",
        "    return \"Logistic Regression\",\"With SMOTE\",roc_auc_lr\n",
        "  else:\n",
        "    return \"Logistic Regression\",\"Without SMOTE\",roc_auc_lr\n",
        "\n",
        "# Predict on the model    \n",
        "model_result=[]\n",
        "model_result.append(logistic_regression())    \n",
        "model_result.append(logistic_regression(imbalance=True))\n",
        "pd.DataFrame(model_result,columns=['Model','SMOTE','ROC_AUC'])"
      ],
      "metadata": {
        "id": "2Fxb5fh_7Mi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomized search for the best C parameter\n",
        "# Split data with SMOTE \n",
        "X_train, X_test, y_train, y_test = data_split(X, y, imbalance = True) \n",
        "\n",
        "# Rescale data\n",
        "X_train_std, X_test_std = rescaling(X_train, X_test, numerical_cols = num_cols)\n",
        "# X_train_std, X_test_std=X_train_std.astype('int')\n",
        "\n",
        "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=42)\n",
        "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1','elasticnet'])\n",
        "clf = RandomizedSearchCV(logistic, distributions, random_state=42)\n",
        "\n",
        "lr_best= clf.fit(X_train_std, y_train)   \n",
        "#print(distributions)\n",
        "print(lr_best.best_params_)"
      ],
      "metadata": {
        "id": "SrafwlUjQ890"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the model AUC_ROC Score\n",
        "scores = cross_val_score(lr_best, X_train_std, y_train, scoring =\"roc_auc\", cv = 5)\n",
        "roc_auc_lr = np.mean(scores)\n",
        "print(f'Roc_Auc score for the Logistic regression with SMOTE :{roc_auc_lr}')"
      ],
      "metadata": {
        "id": "Ss7SPW23RO2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check prrecision recall score\n",
        "precision_recall(lr_best,X_test_std,y_test)     "
      ],
      "metadata": {
        "id": "28GUHKLSRawv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Accuracy**: The propertion of the total number of prediction are correct.\n",
        "2. **Precision**: The proportion of positive prediction that are actually correct.\n",
        "3. **Recall** : The proportion of positive values correctly predicted as such.\n",
        "\n",
        "**In this Project**\n",
        "1. **Accuracy**: Overall how often the model predict corrrectly defaulters or not defaulters.\n",
        "2. **Precision**: when the model predect defaults: How often to correct?\n",
        "3. **Recall**: The propertion of actual defaulters that the model will correctly predect such as.  \n",
        "\n",
        "**which matrics shhuch I use?**\n",
        "\n",
        "1. **False Positive:** A person who will pay predect as defaulters.\n",
        "2. **false negative:**  A person who default predict as payer\n",
        "\n",
        "**False negative arde worse==>look for aa better recall**"
      ],
      "metadata": {
        "id": "hbQ72PbWzR1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "Ds3UmfS6t9l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "def RandomForest(imbalance=False):\n",
        "   X_train, X_test, y_train, y_test=data_split(X,y,imbalance=imbalance)\n",
        "   X_train_std,X_test_std=rescaling(X_train,X_test,numerical_cols = num_cols)\n",
        "   clf_lr = RandomForestClassifier(random_state=42)\n",
        "   clf_lr.fit(X_train_std, y_train)\n",
        "   scores = cross_val_score(clf_lr, X_train_std, y_train, scoring =\"roc_auc\", cv = 5)\n",
        "   roc_auc_lr = np.mean(scores)*100\n",
        "\n",
        "   if imbalance:\n",
        "     return \"Random Forest\",\"With SMOTE\",roc_auc_lr\n",
        "   else:\n",
        "     return \"Random Forest\",\"Without SMOTE\",roc_auc_lr\n",
        "    \n",
        "model_result=[]\n",
        "model_result.append(RandomForest())    \n",
        "model_result.append(RandomForest(imbalance=True))\n",
        "pd.DataFrame(model_result,columns=['Model','Smote','ROC_AUC'])"
      ],
      "metadata": {
        "id": "M4P8dWY8ueLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data with SMOTE\n",
        "X_train_sm, X_test, y_train_sm, y_test = data_split(X, y, imbalance = True)"
      ],
      "metadata": {
        "id": "ivllibvviOBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create parameter grid  \n",
        "param_grid = {\n",
        "    'max_depth': [60, 90, 110],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Instantiate the model\n",
        "clf_rf = RandomForestClassifier()\n",
        "\n",
        "# Instantiate grid search model\n",
        "grid_search = GridSearchCV(estimator = clf_rf, param_grid = param_grid,    \n",
        "                          cv = 2, n_jobs = -1, verbose = 1)\n",
        "\n",
        "# Fit grid search to the data\n",
        "grid_search.fit(X_train_sm, y_train_sm)\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "n8XhYnqriWIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "GXi--n2LilL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the model AUC_ROC Score\n",
        "rf_best = RandomForestClassifier(**grid_search.best_params_)   \n",
        "rf_best.fit(X_train_sm,y_train_sm)\n",
        "\n",
        "scores_best = cross_val_score(rf_best, X_train_sm, y_train_sm, scoring =\"roc_auc\", cv = 3)\n",
        "roc_auc_best = np.mean(scores_best)*100\n",
        "\n",
        "print(f'ROC_AUC training score after tuning for Random Forest: {roc_auc_best:.3f}')"
      ],
      "metadata": {
        "id": "eT_Rzo-ZioXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The F1 score,Precision and Recall value for Random Forest :\")\n",
        "precision_recall(rf_best,X_test,y_test)\n",
        "# precision_score(X_test,y_test)"
      ],
      "metadata": {
        "id": "CY1tIdqTivRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "PXl7ziUeuIDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "def xgboost(imbalance=False):\n",
        "   X_train, X_test, y_train, y_test=data_split(X,y,imbalance=imbalance)\n",
        "   X_train_std,X_test_std=rescaling(X_train,X_test,numerical_cols = num_cols)\n",
        "   clf_lr = XGBClassifier(random_state=42)\n",
        "   clf_lr.fit(X_train_std, y_train)\n",
        "  #  model_xgb.fit(X_train, y_train)\n",
        "   scores = cross_val_score(clf_lr, X_train_std, y_train, scoring =\"roc_auc\", cv = 5)\n",
        "   roc_auc_lr = np.mean(scores)*100\n",
        "  #  print(roc_auc_lr)\n",
        "   if imbalance:\n",
        "     return \"XGBOOST\",\"With SMOTE\",roc_auc_lr\n",
        "   else:\n",
        "     return \"XGBOOST\",\"Without SMOTE\",roc_auc_lr    \n",
        "model_result=[]\n",
        "# y=y.astype('int')\n",
        "model_result.append(xgboost())    \n",
        "model_result.append(xgboost(imbalance=True))\n",
        "pd.DataFrame(model_result,columns=['Model','SMOTE','ROC_AUC'])"
      ],
      "metadata": {
        "id": "DCbt5dyPYjvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data with SMOTE\n",
        "X_train_sm, X_test, y_train_sm, y_test = data_split(X, y, imbalance = True)"
      ],
      "metadata": {
        "id": "GWL1MSqcICAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from skopt.space import Bayes searchCV\n",
        "# from skopt.space import real,categorical,integer\n",
        "params = { \n",
        "    'gamma':0,\n",
        "    'learning_rate':0.01, \n",
        "    'max_depth':3, \n",
        "    'colsample_bytree':0.6,\n",
        "    'subsample':0.8,\n",
        "    'scale_pos_weight':3.5,\n",
        "    'n_estimators':1000,\n",
        "    'objective':'binary:logistic', \n",
        "    'reg_alpha':0.3    \n",
        "}\n",
        "\n",
        "clf_xgb=XGBClassifier(**params)\n",
        "scores_best = cross_val_score(clf_xgb, X_train_sm, y_train_sm, scoring =\"roc_auc\", cv = 3)\n",
        "roc_auc_best = np.mean(scores_best)*100\n",
        "print(f'ROC_AUC training score after tuning for initial parameter in XGBOOST: {roc_auc_best:.3f}')"
      ],
      "metadata": {
        "id": "3RMuF7VrIHLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = np.arange(200,1000,200)\n",
        "\n",
        "# Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
        "# The larger gamma is, the more conservative the algorithm will be\n",
        "gamma = np.arange(0.1,0.6,0.1)\n",
        "\n",
        "# Default 0.3, range(0,1)\n",
        "learning_rate = np.arange(0.1,0.6,0.1)\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = list(range(3,8,1))\n",
        "\n",
        "# Subsample ratio of the training instances.Range(0,1)\n",
        "subsample = np.arange(0.5,0.9,0.1)\n",
        "\n",
        "# Subsample ratio of columns when constructing each tree. Range(0,1)\n",
        "colsample_bytree = np.arange(0.5,0.9,0.1)\n",
        "\n",
        "# Control the balance of positive and negative weights\n",
        "# Sum(negative instances) / sum(positive instances)\n",
        "scale_pos_weight = [1,3.5]\n",
        "\n",
        "\n",
        "# Create the random grid\n",
        "random_grid_xgb = {'n_estimators': n_estimators,\n",
        "                   'gamma': gamma,\n",
        "                   'learning_rate':learning_rate,\n",
        "                   'max_depth': max_depth,\n",
        "                   'subsample':subsample,\n",
        "                   'colsample_bytree':colsample_bytree,\n",
        "                   'scale_pos_weight':scale_pos_weight\n",
        "                  }\n",
        "print(random_grid_xgb)     "
      ],
      "metadata": {
        "id": "5wdGXbHmveSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgboost = XGBClassifier()\n",
        "xgb_random = RandomizedSearchCV(estimator = xgboost, \n",
        "                                param_distributions = random_grid_xgb, \n",
        "                                n_iter = 10, \n",
        "                                cv = 2, \n",
        "                                verbose=1, \n",
        "                                random_state=42, \n",
        "                                n_jobs = -1,\n",
        "                                scoring ='roc_auc')\n",
        "\n",
        "\n",
        "xgb_random.fit(X_train_sm, y_train_sm)   \n",
        "xgb_random.best_params_, xgb_random.best_score_\n",
        "\n",
        "print(xgb_random.best_params_,xgb_random.best_score_)"
      ],
      "metadata": {
        "id": "nNMNd8wEvjZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the model F1 score, Precision and Recall Score\n",
        "print(\"The F1 score, Precision and Recall for XGBOOST is :\")\n",
        "precision_recall(xgb_random,X_test,y_test)\n"
      ],
      "metadata": {
        "id": "T0-hIFR_YQsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plot Confusion Matrix "
      ],
      "metadata": {
        "id": "0T5Lyk6qBDGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feat_imp(X_train, model):\n",
        "    \"\"\"\n",
        "    Prints the model feature importances\n",
        "    \"\"\"\n",
        "    feat_imp = pd.DataFrame(\n",
        "        {\"Feature\": X_train.columns, \"Feature Importance\": model.feature_importances_}\n",
        "    )\n",
        "    feat_imp.sort_values(by=\"Feature Importance\", ascending=False, inplace=True)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(f\"Feature Importance of {model}\", fontsize=14)\n",
        "    ax = sns.barplot(x=\"Feature\", y=\"Feature Importance\", data=feat_imp)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "    plt.show()\n",
        "    \n",
        "def get_model_results(X_train, X_test, y_train, y_test, model, feat_imp=False):\n",
        "    \"\"\"\n",
        "    Prints the training and test metrics and plots the confusion matrices.\n",
        "    Also plots the feature importance based on the user choosing the parameter variable,\n",
        "    and returns the evaluation metrics.\n",
        "    \"\"\"\n",
        "    # Fit training model to training set\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Obtain the predicted values and probabilities from the model\n",
        "    y_train_pred = model.predict(X_train)# y-train predict model\n",
        "    y_train_pred_probs = model.predict_proba(X_train)# y- train probability of model predict\n",
        "\n",
        "    y_test_pred = model.predict(X_test)# y-test predicted\n",
        "    y_test_pred_probs = model.predict_proba(X_test)#y-test predict probility \n",
        "\n",
        "    # Get confusion matrix\n",
        "    train_matrix = metrics.confusion_matrix(y_train, y_train_pred)# y-train,y-train-pred confusion matrix\n",
        "    test_matrix = metrics.confusion_matrix(y_test, y_test_pred) #y-test,y-test-pred confusion matrix\n",
        "\n",
        "    # Get F1 score\n",
        "    f1_train = metrics.f1_score(y_train, y_train_pred)\n",
        "    f1_test = metrics.f1_score(y_test, y_test_pred)\n",
        "\n",
        "    # Print the train and test roc_auc_score\n",
        "    #and test confusion matrix\n",
        "    print(\n",
        "        f\"ROC_AUC_Score of train set is {metrics.roc_auc_score(y_train, y_train_pred_probs[:, 1])}.\"\n",
        "    )\n",
        "    print(\n",
        "        f\"ROC_AUC_Score of test set is {metrics.roc_auc_score(y_test, y_test_pred_probs[:, 1])}.\"\n",
        "    )\n",
        "    #print(\"Confusion matrix of test set\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "    #print(\n",
        "    #    \"Classification Report of test set\\n\",\n",
        "    #    metrics.classification_report(y_test, y_test_pred),\n",
        "    #)\n",
        "    \n",
        "    # Display scores\n",
        "    print(f\"F1 of train set is {f1_train.round(4)}.\")\n",
        "    print(f\"F1 of test set is {f1_test.round(4)}.\")\n",
        "\n",
        "    # Plot training and test confusion matrices\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
        "    train_percent = [\n",
        "        \"{0:.2%}\".format(value)\n",
        "        for value in train_matrix.flatten() / np.sum(train_matrix)\n",
        "    ]\n",
        "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(names, train_percent)]\n",
        "    labels = np.asarray(labels).reshape(2, 2)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.heatmap(train_matrix, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
        "    plt.title(\"Train Set\\n\")\n",
        "\n",
        "    names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
        "    test_percent = [\n",
        "        \"{0:.2%}\".format(value) for value in test_matrix.flatten() / np.sum(test_matrix)\n",
        "    ]\n",
        "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(names, test_percent)]\n",
        "    labels = np.asarray(labels).reshape(2, 2)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.heatmap(test_matrix, annot=labels, fmt=\"\", cmap=\"Blues\")\n",
        "    plt.title(\"Test Set\\n\")\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.2)\n",
        "\n",
        "    #plt.figure(figsize=(7, 4))\n",
        "    #plot_roc_curve(model, X_test, y_test)\n",
        "    #plt.show()\n",
        "\n",
        "    if feat_imp == True:\n",
        "        plot_feat_imp(X_train, model)\n",
        "    elif feat_imp == \"LR\":\n",
        "        # Get feature coefficients\n",
        "        importance = model.coef_[0]\n",
        "\n",
        "        df_feat_imp = pd.DataFrame(\n",
        "            columns=[\"Feature\", \"Feature Importance (Value of Coefficient)\"]\n",
        "        )\n",
        "        \n",
        "        # Attach feature coefficients to labels\n",
        "        for i, v in enumerate(importance):\n",
        "            df_feat_imp = df_feat_imp.append(\n",
        "                {\n",
        "                    \"Feature\": X_train.columns[i],\n",
        "                    \"Feature Importance (Value of Coefficient)\": v,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "            #print(f\"{X_train.columns[i]} Feature: %0d, Score: %.5f\" % (i, v))\n",
        "        \n",
        "        # Sort them by their absolute values in descending order\n",
        "        df_feat_imp = df_feat_imp.reindex(\n",
        "            df_feat_imp[\"Feature Importance (Value of Coefficient)\"]\n",
        "            .abs()\n",
        "            .sort_values(ascending=False)\n",
        "            .index\n",
        "        )\n",
        "        \n",
        "        # Plot a bargraph\n",
        "        plt.figure(figsize=(10, 5)) # plot the grah\n",
        "        plt.title(f\"Feature Importance of {model}\", fontsize=14)\n",
        "        ax = sns.barplot(x=\"Feature\", y=\"Feature Importance (Value of Coefficient)\", data=df_feat_imp)\n",
        "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "        plt.show()\n",
        "        \n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "    return metrics.accuracy_score(y_test, y_test_pred),\\\n",
        "           metrics.precision_score(y_test, y_test_pred),\\\n",
        "           metrics.recall_score(y_test, y_test_pred),\\\n",
        "           metrics.f1_score(y_test, y_test_pred),\\\n",
        "           metrics.roc_auc_score(y_test, y_test_pred_probs[:, 1])\n",
        "\n"
      ],
      "metadata": {
        "id": "iyvSSVFuDzw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Confusion matrix"
      ],
      "metadata": {
        "id": "h-far6v2BUGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a Logistic Regression model\n",
        "log_model = LogisticRegression(random_state=0, max_iter=200)\n",
        "\n",
        "# Train the model on the original data set and diplay the performance\n",
        "acc, prec, rec, f1, auc = get_model_results(X_train, X_test, y_train, y_test, log_model)\n",
        "# log_model.set_title('logistic regression')"
      ],
      "metadata": {
        "id": "Av1Z3jWrD4ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Confusion matrix"
      ],
      "metadata": {
        "id": "fhPsw4tgBdqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest condusion matrix\n",
        "rf_model = RandomForestClassifier(random_state=0)\n",
        "acc, prec, rec, f1, auc = get_model_results(X_train, X_test, y_train, y_test, rf_model)"
      ],
      "metadata": {
        "id": "wyQ3ccWIg60m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost Confusion matrix"
      ],
      "metadata": {
        "id": "TWr2cmnBBn-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating the best model\n",
        "clf_lr = XGBClassifier(random_state=42)\n",
        "\n",
        "# I am using resampled data as I am not using class_weight ={0:1, 1:4} to balance\n",
        "\n",
        "acc, prec, rec, f1, auc = get_model_results(X_train, X_test, y_train, y_test, clf_lr)"
      ],
      "metadata": {
        "id": "MECW_Z8J-_X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementt Dummy Model"
      ],
      "metadata": {
        "id": "ha1RigPfBuBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement dummy model\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "DummyClassifier(strategy='stratified')\n",
        "y_pred_dummy = dummy_clf.predict(X_test)\n",
        "\n",
        "print('Dummy model:')\n",
        "precision_recall(dummy_clf, X_test, y_test)"
      ],
      "metadata": {
        "id": "NRTRFtcHyjUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute precision, recall and threshold of Random Forest\n",
        "\n",
        "y_predict_rf = rf_best.predict_proba(X_test)\n",
        "\n",
        "y_scores_rf = y_predict_rf[:,1]\n",
        "#print(y_scores_rf)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores_rf)\n",
        "#print(precisions)\n",
        "#print(recalls)\n",
        "#print(thresholds)\n",
        "recalls_80 = recalls[np.argmin(recalls >= 0.80)]# Recommend recall score = 0.8\n",
        "precision_80 = precisions[np.argmin(recalls >= 0.80)]\n",
        "threshold_80_recall = thresholds[np.argmin(recalls >= 0.80)]\n",
        "\n",
        "thresholds = np.append(thresholds, 1)\n",
        "\n",
        "recalls_80, precision_80, threshold_80_recall"
      ],
      "metadata": {
        "id": "mAULbwnzymu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importance of winner model - Random Forest\n",
        "\n",
        "fea_df = pd.DataFrame({'Feature': feature_cols, 'Feature importance': rf_best.feature_importances_})\n",
        "fea_df = fea_df.sort_values(by='Feature importance')\n",
        "\n",
        "figure, ax = plt.subplots(figsize = (10,8))\n",
        "fea_df.plot.barh(x='Feature',y='Feature importance', ax=ax)\n",
        "plt.title('Features importance',fontsize=14)\n",
        "     "
      ],
      "metadata": {
        "id": "4mEbnypNJ2vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFWgmmQLS1Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression model has the highest recall but the lowest precision, if the business cares recall the most, then this model is the best candidate. If the balance of recall and precision is the most important metric, then Random Forest is the ideal model. Since Random Forest has slightly lower recall but much higher precision than Logistic Regression, I would recommend Random Forest."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}